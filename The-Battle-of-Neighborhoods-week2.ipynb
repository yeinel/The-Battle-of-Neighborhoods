{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "   # Applied Data Science Capstone", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## *!The Battle of Neighborhoods!*", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 1. Introduction/Business Problem", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**In Costa Rica there is a company that sells tours to places of New York and Toronto, this company wants to offer its customers the possibility of visualizing the similarities and differences between one city and another in order to make a decision based on their travel preferences.**\n\n**So in this project is aimed at tour operators interested in attracting more customers who wish to travel to the cities they offer, with the option to see the functionality between two of the major cities of note america such as Toronto and New York in our case.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### 1.1 Stackeholders", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "1. The project should interest companies that sell tours to different places and can easily recommend cities according to the similarity found with the help of the use of machine learning.\n\n2. People who want to travel and have doubts about the destination to choose because they do not have enough information about destinations to make a decision.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 2. Description of the data to be used to solve the problem", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**For this project we will use the knowledge acquired in course 9 to use the benefits of the Forsquare API to explore data from both cities and neighborhoods, and data that is relevant for people who travel such as coffee shops, hotels, restaurants that can visit and be close, theaters and many places for which to have a choice.**\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**We will also use the data that wikipedia provides about each neighborhood of both cities which can be accessed from: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M.\n\n**Data from the neighborhoods of New York City will be charged from https://cocl.us/new_york_dataset.**\n\n**Both datasets must be joined with data where the geospatial coordinates are available in order to consult and explore the necessary data with the Forsquare API. These data will be loaded from the address http://cocl.us/Geospatial_data with the help of the python requests module**\n\nIt must be prepared and cleaned to apply the algorithms that we will need:\n\n1. First of all we will be working with all Boroughs that are necessary and provide value.\n2. To be able to use the wikipedia data, the first thing is to extract the table with the Borough information and convert it into a dataframe so that we can work with the data as we need it. We will do this with the help of the BeautifulSoup python module\n3. We will also eliminate all rows that have the value of \"Not assigned\" since they do not generate value.\n4. In the case of neighborhoods that have the value of \"Not assigned\" they will be assigned the same value as the \"Borough\" data.\n5. The similutud and differences will be based on the Boroughs, therefore we will group the Borough data and concatenate the values for each neighborhood.\n6. To be able to perform explorations with the Forsquare API we will need to cross the data with the coordinates dataset. The merge of the data will be done through the Postcode column.\n7. With the clean data for both New York and Toronto we can continue with the analysis of the data, the visualization to verify the current distribution of the data, train our machine learning model to generate the clusters and find the differences and similarities between Both cities.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 3. Methodology", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**First  let's download all the dependencies that we will need**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Libraries imported.\n"
                }
            ], 
            "source": "import requests #request API with python\nfrom bs4 import BeautifulSoup # Beautiful Soup is a Python library for pulling data out of HTML and XML files.\nimport numpy as np # library for vectorized computation\nimport pandas as pd # library to process data as dataframes\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\nimport io #Core tools for working with streams\n\nimport json # library to handle JSON files\n\nprint('Libraries imported.')"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - folium=0.5.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    openssl-1.1.1c             |       h516909a_0         2.1 MB  conda-forge\n    folium-0.5.0               |             py_0          45 KB  conda-forge\n    ca-certificates-2019.6.16  |       hecc5488_0         145 KB  conda-forge\n    branca-0.3.1               |             py_0          25 KB  conda-forge\n    altair-3.1.0               |           py36_0         724 KB  conda-forge\n    certifi-2019.6.16          |           py36_1         149 KB  conda-forge\n    vincent-0.4.4              |             py_1          28 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.2 MB\n\nThe following NEW packages will be INSTALLED:\n\n    altair:          3.1.0-py36_0      conda-forge\n    branca:          0.3.1-py_0        conda-forge\n    folium:          0.5.0-py_0        conda-forge\n    vincent:         0.4.4-py_1        conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2019.5.15-0                   --> 2019.6.16-hecc5488_0 conda-forge\n    certifi:         2019.6.16-py36_0              --> 2019.6.16-py36_1     conda-forge\n\nThe following packages will be DOWNGRADED:\n\n    openssl:         1.1.1c-h7b6447c_1             --> 1.1.1c-h516909a_0    conda-forge\n\n\nDownloading and Extracting Packages\nopenssl-1.1.1c       | 2.1 MB    | ##################################### | 100% \nfolium-0.5.0         | 45 KB     | ##################################### | 100% \nca-certificates-2019 | 145 KB    | ##################################### | 100% \nbranca-0.3.1         | 25 KB     | ##################################### | 100% \naltair-3.1.0         | 724 KB    | ##################################### | 100% \ncertifi-2019.6.16    | 149 KB    | ##################################### | 100% \nvincent-0.4.4        | 28 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nfolium imported.\n"
                }
            ], 
            "source": "!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # map rendering library\nprint('folium imported.')"
        }, 
        {
            "source": "### 3.1 Load the data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Load the data that we need for Toronto**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "data loaded\n"
                }, 
                {
                    "execution_count": 46, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postalcode</th>\n      <th>Borough</th>\n      <th>Neighbourhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1A</td>\n      <td>Not assigned</td>\n      <td>Not assigned</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M2A</td>\n      <td>Not assigned</td>\n      <td>Not assigned</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M3A</td>\n      <td>North York</td>\n      <td>Parkwoods</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M4A</td>\n      <td>North York</td>\n      <td>Victoria Village</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Harbourfront</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postalcode           Borough     Neighbourhood\n0        M1A      Not assigned      Not assigned\n1        M2A      Not assigned      Not assigned\n2        M3A        North York         Parkwoods\n3        M4A        North York  Victoria Village\n4        M5A  Downtown Toronto      Harbourfront"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Get the dara required for Toronto from wiki url and then parse with BeautifulSoup finding the table class\nwiki_text = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text # get entire page\nsoup = BeautifulSoup(wiki_text,'lxml') # convert text to xml soup object in order to extract what i need.\ntable_dataset = soup.find('table',{'class':'wikitable'}) # find table with  BeautifulSoup find function\n\ndfs = pd.read_html(str(table_dataset))# Read into a list table html \ndf_toronto = pd.concat(dfs) #then convert to a dataframe\ndf_toronto.rename(columns={'Postcode': 'Postalcode'}, inplace=True)#rename the column\n#-------------------\n#Now we need to load the data for latitude and longitud this will be based on a merge by Postcode colum\n\ncsv_file_content=requests.get(\"http://cocl.us/Geospatial_data\").content#get the csv content with the help of requests module\nlat_long_df=pd.read_csv(io.StringIO(csv_file_content.decode('utf-8'))) #convert into pandas dataframe\nlat_long_df.rename(columns={'Postal Code': 'Postalcode'}, inplace=True)\n\nprint(\"data loaded\")\n\ndf_toronto.head()"
        }, 
        {
            "source": "----\n**Load the data that we need for New York**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Data downloaded!\nData loaded!\n"
                }, 
                {
                    "execution_count": 21, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bronx</td>\n      <td>Wakefield</td>\n      <td>40.894705</td>\n      <td>-73.847201</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bronx</td>\n      <td>Co-op City</td>\n      <td>40.874294</td>\n      <td>-73.829939</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bronx</td>\n      <td>Eastchester</td>\n      <td>40.887556</td>\n      <td>-73.827806</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bronx</td>\n      <td>Fieldston</td>\n      <td>40.895437</td>\n      <td>-73.905643</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bronx</td>\n      <td>Riverdale</td>\n      <td>40.890834</td>\n      <td>-73.912585</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Borough Neighborhood   Latitude  Longitude\n0   Bronx    Wakefield  40.894705 -73.847201\n1   Bronx   Co-op City  40.874294 -73.829939\n2   Bronx  Eastchester  40.887556 -73.827806\n3   Bronx    Fieldston  40.895437 -73.905643\n4   Bronx    Riverdale  40.890834 -73.912585"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#First, download the data.\n!wget -q -O 'newyork_data.json' https://cocl.us/new_york_dataset\nprint('Data downloaded!')\n\n#Next, let's load the data.\nwith open('newyork_data.json') as json_data:\n    newyork_data = json.load(json_data)\n\n#In this case the relevant data is in the features key, which is basically a list of the neighborhoods. So, let's define a new variable that includes this data.\nneighborhoods_data = newyork_data['features']\n\n#then we need to tranform the data that is in a json format into a pandas dataframe\n# define the dataframe columns\ncolumn_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the dataframe\ndf_newyork = pd.DataFrame(columns=column_names)\n\n#Then let's loop through the data and fill the dataframe one row at a time.\nfor data in neighborhoods_data:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    \n    df_newyork = df_newyork.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)\n    \nprint('Data loaded!')\ndf_newyork.head()"
        }, 
        {
            "source": "### 3.2 Clear and format the data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "__This process is very important because we need to preparate and format the data in order to be posible to analyse and apply the algoritms that we need__", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**Format the data for Toronto**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 54, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Now we have 103 rows and 5 columns. Shape: (103, 5)\n"
                }, 
                {
                    "execution_count": 54, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postalcode</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Rouge, Malvern</td>\n      <td>43.806686</td>\n      <td>-79.194353</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>Scarborough</td>\n      <td>Highland Creek, Rouge Hill, Port Union</td>\n      <td>43.784535</td>\n      <td>-79.160497</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>Scarborough</td>\n      <td>Guildwood, Morningside, West Hill</td>\n      <td>43.763573</td>\n      <td>-79.188711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>Scarborough</td>\n      <td>Woburn</td>\n      <td>43.770992</td>\n      <td>-79.216917</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>Scarborough</td>\n      <td>Cedarbrae</td>\n      <td>43.773136</td>\n      <td>-79.239476</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postalcode      Borough                            Neighborhood   Latitude  \\\n0        M1B  Scarborough                          Rouge, Malvern  43.806686   \n1        M1C  Scarborough  Highland Creek, Rouge Hill, Port Union  43.784535   \n2        M1E  Scarborough       Guildwood, Morningside, West Hill  43.763573   \n3        M1G  Scarborough                                  Woburn  43.770992   \n4        M1H  Scarborough                               Cedarbrae  43.773136   \n\n   Longitude  \n0 -79.194353  \n1 -79.160497  \n2 -79.188711  \n3 -79.216917  \n4 -79.239476  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\ndf_toronto = df_toronto[df_toronto['Borough'] != 'Not assigned'].reset_index(drop=True)\n\n#rename the column Neighbourhood to be consistent with the New York data\ndf_toronto.rename(columns={'Neighbourhood': 'Neighborhood'}, inplace=True)\n\n#More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, you will notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma as shown in row 11 in the above table.\ndf_toronto = df_toronto.groupby(['Postalcode','Borough'], sort=False).agg( ', '.join).reset_index()\n\n#If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough. So for the 9th cell in the table on the Wikipedia page, the value of the Borough and the Neighborhood columns will be Queen's Park.\nfor index, data_row in df_toronto.iterrows():\n    if data_row['Neighborhood'] == 'Not assigned':\n        data_row['Neighborhood'] = data_row['Borough']\n\n#Then we can merge the tables\ndf_toronto = pd.merge(lat_long_df, df_toronto, on='Postalcode')\ndf_toronto = df_toronto[['Postalcode', 'Borough', 'Neighborhood', 'Latitude', 'Longitude']]#change the columns order\n\n#Now we have 103 rows and 5 columns\nprint(\"Now we have 103 rows and 5 columns. Shape:\",df_toronto.shape)\n\n#show the results\ndf_toronto.head()"
        }, 
        {
            "source": "-------------", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\n\n\n\n\n**Format the data for New York**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 66, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 66, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Queens           81\nBrooklyn         70\nStaten Island    63\nBronx            52\nManhattan        40\nName: Borough, dtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df_newyork['Borough'].value_counts()"
        }, 
        {
            "source": "### 3.3 Analysis and data exploration", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}